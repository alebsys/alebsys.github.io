<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Long way to the application, №2. | Performance Matters</title>
<meta name=keywords content="network,linux,virtualization,tcp,tuning"><meta name=description content="Привет!
Продолжаем изучать маршрут сетевого пакета по подсистемам ядра linux.
В первой части мы разобрали отрезок от сетевой карты гипервизора до txqueue - очередь перед виртуальной машиной в которой и крутится наш сервис.
Теперь разберем следующий отрезок - от сетевой карты ВМ и до самого приложения.
RX queue Процесс обработки трафика виртуальной машиной идентичен с гипервизоров - softirqd демоны разгребают RX очереди. Ничего нового.
Различия начинаются на уровнях сетевого стека, точнее перед ним."><meta name=author content><link rel=canonical href=https://alebsys.github.io/posts/long-way-to-the-app-2/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.c430ebc989de9834deb71350267c02556038b4e0700f26e58a65099aaeaadc8e.css integrity="sha256-xDDryYnemDTetxNQJnwCVWA4tOBwDyblimUJmq6q3I4=" rel="preload stylesheet" as=style><link rel=icon href=https://alebsys.github.io/images/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://alebsys.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://alebsys.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://alebsys.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://alebsys.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://alebsys.github.io/posts/long-way-to-the-app-2/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-VDR541GTVE"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-VDR541GTVE")}</script><meta property="og:title" content="Long way to the application, №2."><meta property="og:description" content="Привет!
Продолжаем изучать маршрут сетевого пакета по подсистемам ядра linux.
В первой части мы разобрали отрезок от сетевой карты гипервизора до txqueue - очередь перед виртуальной машиной в которой и крутится наш сервис.
Теперь разберем следующий отрезок - от сетевой карты ВМ и до самого приложения.
RX queue Процесс обработки трафика виртуальной машиной идентичен с гипервизоров - softirqd демоны разгребают RX очереди. Ничего нового.
Различия начинаются на уровнях сетевого стека, точнее перед ним."><meta property="og:type" content="article"><meta property="og:url" content="https://alebsys.github.io/posts/long-way-to-the-app-2/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-05-14T00:00:00+00:00"><meta property="article:modified_time" content="2024-05-14T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Long way to the application, №2."><meta name=twitter:description content="Привет!
Продолжаем изучать маршрут сетевого пакета по подсистемам ядра linux.
В первой части мы разобрали отрезок от сетевой карты гипервизора до txqueue - очередь перед виртуальной машиной в которой и крутится наш сервис.
Теперь разберем следующий отрезок - от сетевой карты ВМ и до самого приложения.
RX queue Процесс обработки трафика виртуальной машиной идентичен с гипервизоров - softirqd демоны разгребают RX очереди. Ничего нового.
Различия начинаются на уровнях сетевого стека, точнее перед ним."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://alebsys.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Long way to the application, №2.","item":"https://alebsys.github.io/posts/long-way-to-the-app-2/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Long way to the application, №2.","name":"Long way to the application, №2.","description":"Привет!\nПродолжаем изучать маршрут сетевого пакета по подсистемам ядра linux.\nВ первой части мы разобрали отрезок от сетевой карты гипервизора до txqueue - очередь перед виртуальной машиной в которой и крутится наш сервис.\nТеперь разберем следующий отрезок - от сетевой карты ВМ и до самого приложения.\nRX queue Процесс обработки трафика виртуальной машиной идентичен с гипервизоров - softirqd демоны разгребают RX очереди. Ничего нового.\nРазличия начинаются на уровнях сетевого стека, точнее перед ним.","keywords":["network","linux","virtualization","tcp","tuning"],"articleBody":"Привет!\nПродолжаем изучать маршрут сетевого пакета по подсистемам ядра linux.\nВ первой части мы разобрали отрезок от сетевой карты гипервизора до txqueue - очередь перед виртуальной машиной в которой и крутится наш сервис.\nТеперь разберем следующий отрезок - от сетевой карты ВМ и до самого приложения.\nRX queue Процесс обработки трафика виртуальной машиной идентичен с гипервизоров - softirqd демоны разгребают RX очереди. Ничего нового.\nРазличия начинаются на уровнях сетевого стека, точнее перед ним.\ninput_pkt_queue После RXq пакет прибывает к input_pkt_queue - очередь перед стеком протоколов TCP/IP.\nПереполнение input_pkt_queue ведет к росту значения во второй колонке файла /proc/net/softnet_stat, а node_exporter содержит метрику node_softnet_dropped_total.\nУзнать максимальную длину, а так же изменить значение можно командой sysctl net.core.netdev_max_backlog.\nТеперь поднимемся на уровень TCP протокола.\nесли создается новое соединение… Для обмена данными, например по HTTP, предварительно требуется установить соединение. Этот процесс называют tcp three-way handshake.\nПри инициализации соединение меняет свое состояние, например SYN_RECV-\u003eESTABLISHED для server или SYN_SENT-\u003eESTABLISHED для client.\nВведем еще две очереди - SYN Queue и Accept Queue.\nПроцесс со стороны server:\nпоступает SYN пакет; соединение переходит в состояние SYN_RECV и попадает в SYN Queue; SYN-ACK пакет направляется к client; поступает клиентский ACK; соединение переходит в состояние ESTABLISHED и перемещается в Accept Queue; приложение асинхронно вызывает accept() и начинает обслуживать Подробно процесс описан в блоге alibaba cloud.\nНаблюдение:\nSYN Queue\nnetstat -s | grep -i \"listen\" node_netstat_TcpExt_ListenDrops метрика в node_exporter Accept Queue\nss -ntl - текущий размер очереди (Recv-Q) и максимальный размер очереди (Send-Q) netstat -s | grep -i \"listen\" node_netstat_TcpExt_ListenOverflows метрика в node_exporter Тюнинг\nSYN Queue\nВ ядрах версий 2.6.20+ вычислить значение непросто:\nbacklog = min(somaxconn, backlog) nr_table_entries = backlog nr_table_entries = min(backlog, sysctl_max_syn_backlog) nr_table_entries = max(nr_table_entries, 8) // roundup_pow_of_two: 将参数向上取整到最小的 2^n，注意这里存在一个 +1 nr_table_entries = roundup_pow_of_two(nr_table_entries + 1) max_qlen_log = max(3, log2(nr_table_entries)) max_queue_length = 2^max_qlen_log Для упрощения вычисления можно по-прежнему ориентироваться на файл /proc/sys/net/ipv4/tcp_max_syn_backlog, но о нюансах стоит помнить.\nAccept Queue\nmin(somaxconn, backlog,sysctl_max_syn_backlog), где somaxconn - /proc/sys/net/core/somaxconn backlog - параметр системного вызова int listen(int sockfd, int backlog) например в nginx существует одноименная директива backlog. если соединение уже установлено… Напомню, что TCP протокол гарантирует надежную доставку и правильный порядок следования пакетов. Для этого проверяется их порядковый номер - sequence number или SYN.\nЕсли порядок следования не нарушается, то пакет помещается напрямую в буфер сокета (recvQ). В противном случае в OFO Queue (out of order), где он дожидается запоздавших соседей и восстановления порядка следования. Только после этого пакет отправят в recvQ.\nOut of order пакеты негативно влияют на производительность:\nпровоцируют механизм fast retransmits, а значит понижают объем полезного трафика, т.н. goodput; повышают latency - тратится время на ожидание и восстановление правильного порядка следования пакетов. Причины возникновения могут быть в нескольких маршрутов в рамках одного TCP потока и/или при потерях на сетевом оборудовании.\nПроблематика out of order пакетов обсуждалась в докладе Тюним память и сетевой стек в Linux / Дмитрий Самсонов (Одноклассники), советую ознакомиться.\nНаблюдение\nOFO Queue\nnetstat -s | grep -E 'TCPOFOQueue|TCPOFODrop' метрики node_exporter: node_netstat_TcpExt_TCPOFOQueue - объем поступающих OFO пакетов; node_netstat_TcpExt_TCPOFODrop - дропы пакетов при переполнении; в релизе node_exporter 1.8.0 версии метрика TCPOFOQueue стала дефолтной для коллектора netstat.\nrecvQ\nnetstat -s | grep -E 'TCPRcvQDrop|TCPRcvCollapsed' - дропы пакетов при переполнении сокета; метрики node_exporter: node_netstat_TcpExt_TCPRcvQDrop - дропы пакетов при переполнении сокета; node_netstat_TcpExt_TCPRcvCollapsed - прежде чем дропать при переполнении сокета, ядро “из последних сил” пытается стабилизировать ситуацию. В свое время ребята из Cloudflare провели исследование как TCP collapse влияет на производительность, must read.\nТюнинг\nOFO Queue значение задается при создании сокета через системный вызов sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_REORDERING, 65536)\nrecvQ\nnet.ipv4.tcp_mem - объем памяти всех tcp буферов в системе net.core.rmem_max - объем памяти tcp буферов приема в системе net.ipv4.tcp_rmem - объем конкретного экземпляра tcp буфера В следующей части соберем всё воедино и сделаем дашборд для удобного наблюдения за каждым из компонентов.\nУдачи!\n","wordCount":"613","inLanguage":"en","datePublished":"2024-05-14T00:00:00Z","dateModified":"2024-05-14T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://alebsys.github.io/posts/long-way-to-the-app-2/"},"publisher":{"@type":"Organization","name":"Performance Matters","logo":{"@type":"ImageObject","url":"https://alebsys.github.io/images/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://alebsys.github.io/ accesskey=h title="Performance Matters (Alt + H)"><img src=https://alebsys.github.io/images/favicon.ico alt aria-label=logo height=35>Performance Matters</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://alebsys.github.io/about/ title=About><span>About</span></a></li><li><a href=https://alebsys.github.io/posts/ title=Blog><span>Blog</span></a></li><li><a href=https://alebsys.github.io/for_hr/ title="For HR"><span>For HR</span></a></li><li><a href=https://alebsys.github.io/mentoring/ title=Mentoring><span>Mentoring</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://alebsys.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://alebsys.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Long way to the application, №2.</h1><div class=post-meta><span title='2024-05-14 00:00:00 +0000 UTC'>May 14, 2024</span>&nbsp;·&nbsp;3 min</div></header><div class=post-content><p>Привет!</p><p>Продолжаем изучать маршрут сетевого пакета по подсистемам ядра <strong>linux</strong>.<br><a href=https://alebsys.github.io/posts/long-way-to-the-app-1/>В первой части</a> мы разобрали отрезок от сетевой карты гипервизора до <code>txqueue</code> - очередь перед виртуальной машиной в которой и крутится наш сервис.</p><p>Теперь разберем следующий отрезок - от сетевой карты ВМ и до самого приложения.</p><hr><h3 id=rx-queue>RX queue<a hidden class=anchor aria-hidden=true href=#rx-queue>#</a></h3><p><img loading=lazy src=/images/long-way-to-the-app31.png alt="network packet path"></p><p>Процесс обработки трафика виртуальной машиной идентичен с гипервизоров - <code>softirqd</code> демоны разгребают <code>RX</code> очереди. Ничего нового.</p><p>Различия начинаются на уровнях сетевого стека, точнее перед ним.</p><h3 id=input_pkt_queue>input_pkt_queue<a hidden class=anchor aria-hidden=true href=#input_pkt_queue>#</a></h3><p><img loading=lazy src=/images/long-way-to-the-app32.png alt="network packet path"></p><p>После <code>RXq</code> пакет прибывает к <code>input_pkt_queue</code> - очередь перед стеком протоколов <strong>TCP/IP</strong>.</p><p>Переполнение <code>input_pkt_queue</code> ведет к росту значения во второй колонке файла <a href=https://insights-core.readthedocs.io/en/latest/shared_parsers_catalog/softnet_stat.html><code>/proc/net/softnet_stat</code></a>, а <strong>node_exporter</strong> содержит метрику <code>node_softnet_dropped_total</code>.</p><p>Узнать максимальную длину, а так же изменить значение можно командой <code>sysctl net.core.netdev_max_backlog</code>.</p><p>Теперь поднимемся на уровень <strong>TCP</strong> протокола.</p><h3 id=если-создается-новое-соединение>если создается новое соединение&mldr;<a hidden class=anchor aria-hidden=true href=#если-создается-новое-соединение>#</a></h3><p><img loading=lazy src=/images/long-way-to-the-app45.png alt="network packet path"></p><p>Для обмена данными, например по HTTP, предварительно требуется установить соединение. Этот процесс называют <a href=https://en.wikipedia.org/wiki/Transmission_Control_Protocol#Connection_establishment>tcp three-way handshake</a>.</p><p>При инициализации соединение меняет свое состояние, например <code>SYN_RECV->ESTABLISHED</code> для <strong>server</strong> или <code>SYN_SENT->ESTABLISHED</code> для <strong>client</strong>.</p><p>Введем еще две очереди - <code>SYN Queue</code> и <code>Accept Queue</code>.</p><p>Процесс со стороны <strong>server</strong>:</p><ul><li>поступает <code>SYN</code> пакет;</li><li>соединение переходит в состояние <code>SYN_RECV</code> и попадает в <code>SYN Queue</code>;</li><li><code>SYN-ACK</code> пакет направляется к <strong>client</strong>;</li><li>поступает клиентский <code>ACK</code>;</li><li>соединение переходит в состояние <code>ESTABLISHED</code> и перемещается в <code>Accept Queue</code>;</li><li>приложение асинхронно вызывает <code>accept()</code> и начинает обслуживать</li></ul><p>Подробно процесс описан в <a href=https://www.alibabacloud.com/blog/tcp-syn-queue-and-accept-queue-overflow-explained_599203>блоге alibaba cloud</a>.</p><p><strong>Наблюдение</strong>:</p><p><code>SYN Queue</code></p><ul><li><code>netstat -s | grep -i "listen"</code></li><li><code>node_netstat_TcpExt_ListenDrops</code> метрика в <strong>node_exporter</strong></li></ul><p><code>Accept Queue</code></p><ul><li><code>ss -ntl</code> - текущий размер очереди (<code>Recv-Q</code>) и максимальный размер очереди (<code>Send-Q</code>)</li><li><code>netstat -s | grep -i "listen"</code></li><li><code>node_netstat_TcpExt_ListenOverflows</code> метрика в <strong>node_exporter</strong></li></ul><p><strong>Тюнинг</strong></p><p><code>SYN Queue</code></p><p>В ядрах версий 2.6.20+ вычислить значение непросто:</p><pre tabindex=0><code>    backlog = min(somaxconn, backlog)
    nr_table_entries = backlog
    nr_table_entries = min(backlog, sysctl_max_syn_backlog)
    nr_table_entries = max(nr_table_entries, 8)
    // roundup_pow_of_two: 将参数向上取整到最小的 2^n，注意这里存在一个 +1
    nr_table_entries = roundup_pow_of_two(nr_table_entries + 1)
    max_qlen_log = max(3, log2(nr_table_entries))
    max_queue_length = 2^max_qlen_log
</code></pre><p>Для упрощения вычисления можно по-прежнему ориентироваться на файл <code>/proc/sys/net/ipv4/tcp_max_syn_backlog</code>, но о нюансах стоит помнить.</p><p><code>Accept Queue</code></p><ul><li><code>min(somaxconn, backlog,sysctl_max_syn_backlog)</code>, где<ul><li><code>somaxconn</code> - <code>/proc/sys/net/core/somaxconn</code></li><li><code>backlog</code> - параметр системного вызова <code>int listen(int sockfd, int backlog)</code><ul><li>например в <strong>nginx</strong> существует одноименная директива <code>backlog</code>.</li></ul></li></ul></li></ul><h3 id=если-соединение-уже-установлено>если соединение уже установлено&mldr;<a hidden class=anchor aria-hidden=true href=#если-соединение-уже-установлено>#</a></h3><p><img loading=lazy src=/images/long-way-to-the-app46.png alt="network packet path"></p><p>Напомню, что <strong>TCP</strong> протокол гарантирует надежную доставку и правильный порядок следования пакетов. Для этого проверяется их порядковый номер - <strong>sequence number</strong> или <code>SYN</code>.</p><p>Если порядок следования не нарушается, то пакет помещается напрямую в буфер сокета (<code>recvQ</code>). В противном случае в <code>OFO Queue</code> (out of order), где он дожидается запоздавших соседей и восстановления порядка следования. Только после этого пакет отправят в <code>recvQ</code>.</p><p><strong>Out of order</strong> пакеты негативно влияют на производительность:</p><ul><li>провоцируют <a href=https://arthurchiao.art/blog/tcp-retransmission-may-be-misleading/>механизм fast retransmits</a>, а значит понижают объем полезного трафика, т.н. <a href=https://en.wikipedia.org/wiki/Goodput>goodput</a>;</li><li>повышают latency - тратится время на ожидание и восстановление правильного порядка следования пакетов.</li></ul><p>Причины возникновения могут быть в нескольких маршрутов в рамках одного <strong>TCP</strong> потока и/или при потерях на сетевом оборудовании.</p><p>Проблематика out of order пакетов обсуждалась в докладе <a href="https://youtu.be/ynGKVeIAPnk?si=DbVY_g5BjG3tl1YG">Тюним память и сетевой стек в Linux / Дмитрий Самсонов (Одноклассники)</a>, советую ознакомиться.</p><p><strong>Наблюдение</strong></p><p><code>OFO Queue</code></p><ul><li><code>netstat -s | grep -E 'TCPOFOQueue|TCPOFODrop'</code></li><li>метрики <strong>node_exporter</strong>:<ul><li><code>node_netstat_TcpExt_TCPOFOQueue</code> - объем поступающих <code>OFO</code> пакетов;</li><li><code>node_netstat_TcpExt_TCPOFODrop</code> - дропы пакетов при переполнении;</li></ul></li></ul><blockquote><p>в релизе <a href=https://github.com/prometheus/node_exporter/releases/tag/v1.8.0>node_exporter 1.8.0 версии</a> метрика <code>TCPOFOQueue</code> стала дефолтной для коллектора netstat.</p></blockquote><p><code>recvQ</code></p><ul><li><code>netstat -s | grep -E 'TCPRcvQDrop|TCPRcvCollapsed'</code> - дропы пакетов при переполнении сокета;</li><li>метрики <strong>node_exporter</strong>:<ul><li><code>node_netstat_TcpExt_TCPRcvQDrop</code> - дропы пакетов при переполнении сокета;</li><li><code>node_netstat_TcpExt_TCPRcvCollapsed</code> - прежде чем дропать при переполнении сокета, ядро &ldquo;из последних сил&rdquo; пытается стабилизировать ситуацию.</li></ul></li></ul><p>В свое время ребята из Cloudflare провели <a href=https://blog.cloudflare.com/unbounded-memory-usage-by-tcp-for-receive-buffers-and-how-we-fixed-it>исследование</a> как <code>TCP collapse</code> влияет на производительность, must read.</p><p><strong>Тюнинг</strong></p><p><code>OFO Queue</code> значение задается при создании сокета через системный вызов <code>sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_REORDERING, 65536)</code></p><p><code>recvQ</code></p><ul><li><code>net.ipv4.tcp_mem</code> - объем памяти всех tcp буферов в системе</li><li><code>net.core.rmem_max</code> - объем памяти tcp буферов <strong>приема</strong> в системе</li><li><code>net.ipv4.tcp_rmem</code> - объем конкретного экземпляра tcp буфера</li></ul><hr><p>В следующей части соберем всё воедино и сделаем дашборд для удобного наблюдения за каждым из компонентов.</p><p>Удачи!</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://alebsys.github.io/tags/network/>Network</a></li><li><a href=https://alebsys.github.io/tags/linux/>Linux</a></li><li><a href=https://alebsys.github.io/tags/virtualization/>Virtualization</a></li><li><a href=https://alebsys.github.io/tags/tcp/>Tcp</a></li><li><a href=https://alebsys.github.io/tags/tuning/>Tuning</a></li></ul></footer><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//https-alebsys-github-io.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></article></main><footer class=footer><span>&copy; 2024 <a href=https://alebsys.github.io/>Performance Matters</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>